## Сверточная нейронная сеть (convolutional neural network)

Сверточная нейросеть (CNN) — это тип искусственной нейронной сети, который особенно хорош для работы с изображениями. Представь, что ты смотришь на картину, и твоя задача — понять, что на ней изображено. Сначала ты можешь заметить крупные детали, например, цвет или формы, а затем, постепенно, разбираться в более мелких частях, таких как текстуры или границы объектов.

Сверточные нейросети работают по схожему принципу. Они используют свертки, чтобы "разбивать" изображение на небольшие участки и искать признаки, такие как края, углы, текстуры и другие особенности. С каждым слоем сети эти признаки становятся всё более сложными, и в итоге сеть может точно классифицировать изображение или делать другие задачи (например, распознавание объектов).

Главная особенность таких сетей — это сверточные слои, которые помогают сети автоматически извлекать важные детали из изображения, не требуя от нас много предварительных знаний.

### **Подробное описание кода**

Этот код выполняет задачу классификации изображений глаз с использованием сверточной нейронной сети (CNN) в TensorFlow. Разберем его поэтапно.

---

## **1. Импорт необходимых библиотек**
```python
import os
import pathlib
import zipfile

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report
```
### **Назначение импортируемых библиотек:**
- `os`, `pathlib`, `zipfile` — работа с файловой системой (поиск файлов, переименование, распаковка ZIP).
- `numpy` — работа с массивами данных.
- `matplotlib.pyplot`, `seaborn` — построение графиков (включая матрицу путанности).
- `tensorflow` — разработка и обучение нейросетей.
- `sklearn.metrics` — оценка качества классификации (матрица путанности и отчёт по метрикам).

---

## **2. Функция переименования изображений**
```python
def rename_images_in_directory(directory, prefix="img"):
    """
    Переименовывает все изображения в указанной директории и её подпапках,
    присваивая им последовательные имена в формате "img_номер.расширение".
    """
    if not os.path.isdir(directory):
        print(f"Ошибка: Папка '{directory}' не найдена.")
        return

    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
    image_files = []

    # Поиск всех изображений в папке и её подпапках
    for root, _, files in os.walk(directory):
        for file in files:
            if os.path.splitext(file)[1].lower() in image_extensions:
                image_files.append(os.path.join(root, file))

    # Сортировка файлов для стабильного порядка нумерации
    image_files.sort()

    # Переименование файлов
    for index, old_path in enumerate(image_files, start=1):
        directory, filename = os.path.split(old_path)
        ext = os.path.splitext(filename)[1]
        new_name = f"{prefix}_{index}{ext}"
        new_path = os.path.join(directory, new_name)

        if old_path != new_path:
            os.rename(old_path, new_path)
            print(f"Renamed: {old_path} -> {new_path}")
```
### **Что делает функция?**
1. Проверяет, существует ли указанная папка.
2. Собирает список всех изображений в директории и её подпапках.
3. Сортирует файлы для согласованности нумерации.
4. Присваивает файлам новые имена в формате `img_номер.расширение`.
5. Выполняет переименование.

---

## **3. Загрузка и распаковка данных**
```python
Type_of_eyes_url = (
    "https://drive.google.com/uc?export=download&id=1nsD3EqrTYl_GE2WO7dloJ6QSyNQGtzfq"
)

zip_path = tf.keras.utils.get_file('Type_of_eyes.zip', origin=Type_of_eyes_url, extract=False)
print(f"Zip file downloaded to: {zip_path}")
```
### **Что здесь происходит?**
- Ссылка `Type_of_eyes_url` указывает на архив с изображениями глаз, расположенный на Google Drive.
- `tf.keras.utils.get_file()` скачивает ZIP-архив в кэшированное место.

---

### **4. Распаковка и переименование файлов**
```python
extracted_path = pathlib.Path(zip_path).parent / "Type_of_eyes"

if not extracted_path.is_dir():
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extracted_path)
    print(f"Files extracted to: {extracted_path}")
    rename_images_in_directory(extracted_path)
```
### **Что здесь происходит?**
- Создается путь для распаковки архива.
- Если папка не существует, выполняется распаковка.
- Затем вызывается функция `rename_images_in_directory()`, чтобы файлы имели стандартизированные имена.

---

## **5. Подготовка данных для обучения**
```python
data_dir = pathlib.Path(f"{extracted_path}/Type_of_eyes")

# Размер изображений
img_height, img_width = 180, 180
batch_size = 32
```
- `data_dir` указывает на папку, где лежат изображения, разделённые по категориям.
- `img_height`, `img_width` — размер изображений, к которому они будут приведены.
- `batch_size` — количество изображений в одной партии для обучения.

---

## **6. Загрузка данных в формате TensorFlow Dataset**
```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)
```
- Датасет создается автоматически из директорий.
- `validation_split=0.2` — 80% данных идёт на обучение, 20% — на валидацию.
- `seed=123` фиксирует случайность для воспроизводимости.

---

## **7. Нормализация данных**
```python
normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)

train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
```
- Все пиксели изображений переводятся в диапазон `[0,1]`, чтобы улучшить обучение модели.

---

## **8. Оптимизация загрузки данных**
```python
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```
- `cache()` кэширует данные, чтобы ускорить обучение.
- `shuffle(1000)` перемешивает данные для разнообразия.
- `prefetch(AUTOTUNE)` подгружает данные заранее.

---

## **9. Создание модели CNN**
```python
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(class_names), activation='softmax'),
])
```
- 3 сверточных слоя с увеличивающимся количеством фильтров.
- Функция активации `ReLU`.
- `MaxPooling2D()` уменьшает размерность карт признаков.
- `Flatten()` превращает 2D-данные в вектор.
- `Dense(128)` — полносвязный слой.
- `Dense(len(class_names), activation='softmax')` — выходной слой с вероятностями классов.

---

## **10. Обучение модели**
```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
epochs = 10
history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)
```
- `adam` — оптимизатор.
- `sparse_categorical_crossentropy` — функция потерь.
- `epochs=10` — число эпох.

---

## **11. Оценка модели**
```python
y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))
```
- Собираем реальные (`y_true`) и предсказанные (`y_pred`) классы.

---

## **12. Построение матрицы путанности**
```python
conf_mat = confusion_matrix(y_true, y_pred)
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.show()
```
- Визуализация ошибок классификации.

---

## **13. Вывод отчёта**
```python
print(classification_report(y_true, y_pred, target_names=class_names))
```
- Точность, полнота и F1-метрика для каждого класса.

### **Подробное построчное объяснение кода**

Этот код выполняет задачу классификации изображений глаз, используя сверточную нейронную сеть (CNN) в TensorFlow. Разберем код **построчно и по блокам**, чтобы понять каждую операцию.

---

## **1. Импорт необходимых библиотек**
```python
import os
import pathlib
import zipfile

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report
```
**Что делает каждая строка?**
- `import os` — модуль для работы с файловой системой (переименование, проверка директорий и файлов).
- `import pathlib` — удобная работа с путями файлов и папок в кроссплатформенном формате.
- `import zipfile` — позволяет распаковывать `.zip` файлы.
- `import numpy as np` — `NumPy` используется для работы с многомерными массивами данных.
- `import matplotlib.pyplot as plt` — библиотека для построения графиков.
- `import seaborn as sns` — более удобная и красивая визуализация данных (например, для матрицы путанности).
- `import tensorflow as tf` — основная библиотека для работы с нейросетями.
- `from sklearn.metrics import confusion_matrix, classification_report`  
  - `confusion_matrix` — строит матрицу ошибок модели.
  - `classification_report` — рассчитывает точность (precision), полноту (recall) и F1-метрики.

---

## **2. Функция переименования изображений**
```python
def rename_images_in_directory(directory, prefix="img"):
```
- Определяем функцию `rename_images_in_directory`, которая принимает два параметра:
  - `directory` — путь к папке, где находятся изображения.
  - `prefix="img"` — префикс, который будет добавляться к каждому новому имени файла.

```python
    if not os.path.isdir(directory):
        print(f"Ошибка: Папка '{directory}' не найдена.")
        return
```
- Проверяем, существует ли папка `directory`. Если нет — выводим сообщение об ошибке и завершаем выполнение.

```python
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
    image_files = []
```
- `image_extensions` содержит список допустимых форматов изображений.
- `image_files = []` создаёт пустой список для хранения путей к изображениям.

```python
    for root, _, files in os.walk(directory):
        for file in files:
            if os.path.splitext(file)[1].lower() in image_extensions:
                image_files.append(os.path.join(root, file))
```
- `os.walk(directory)` рекурсивно проходит по всем файлам в папке `directory` и её подпапках.
- `os.path.splitext(file)[1].lower()` получает расширение файла в нижнем регистре.
- Если расширение есть в `image_extensions`, добавляем полный путь к файлу в `image_files`.

```python
    image_files.sort()
```
- Сортируем файлы по имени, чтобы обеспечить одинаковый порядок переименования.

```python
    for index, old_path in enumerate(image_files, start=1):
        directory, filename = os.path.split(old_path)
        ext = os.path.splitext(filename)[1]
        new_name = f"{prefix}_{index}{ext}"
        new_path = os.path.join(directory, new_name)

        if old_path != new_path:
            os.rename(old_path, new_path)
            print(f"Renamed: {old_path} -> {new_path}")
```
- Проходим по файлам, переименовываем их в формате `img_номер.расширение` (`img_1.jpg`, `img_2.jpg`, ...).
- Если новое имя отличается от старого — выполняем переименование.

---

## **3. Загрузка и распаковка ZIP-файла**
```python
Type_of_eyes_url = (
    "https://drive.google.com/uc?export=download&id=1nsD3EqrTYl_GE2WO7dloJ6QSyNQGtzfq"
)
```
- Указываем URL для скачивания архива с изображениями.

```python
zip_path = tf.keras.utils.get_file('Type_of_eyes.zip', origin=Type_of_eyes_url, extract=False)
print(f"Zip file downloaded to: {zip_path}")
```
- Скачиваем файл с помощью `tf.keras.utils.get_file()`, сохраняя его в `zip_path`.
- Выводим сообщение с указанием пути скачанного архива.

```python
extracted_path = pathlib.Path(zip_path).parent / "Type_of_eyes"

if not extracted_path.is_dir():
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extracted_path)
    print(f"Files extracted to: {extracted_path}")
    rename_images_in_directory(extracted_path)
```
- Определяем `extracted_path`, где будут храниться распакованные файлы.
- Если папка `extracted_path` не существует:
  - Распаковываем архив с помощью `zipfile.ZipFile()`.
  - Переименовываем изображения.

---

## **4. Подготовка данных для TensorFlow**
```python
data_dir = pathlib.Path(f"{extracted_path}/Type_of_eyes")
```
- Указываем путь к директории с изображениями.

```python
img_height, img_width = 180, 180
batch_size = 32
```
- Определяем размер изображений для приведения к единому формату.
- `batch_size=32` — сколько изображений будет загружаться за раз.

```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir, validation_split=0.2, subset="training", seed=123,
    image_size=(img_height, img_width), batch_size=batch_size,
)
```
- Загружаем изображения, выделяя 80% на обучение (`subset="training"`).

```python
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir, validation_split=0.2, subset="validation", seed=123,
    image_size=(img_height, img_width), batch_size=batch_size,
)
```
- Выделяем 20% данных для валидации.

---

## **5. Подготовка данных перед подачей в модель**
```python
normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)
```
- Приводим значения пикселей к диапазону `[0,1]` (изначально `[0, 255]`).

```python
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
```
- Применяем нормализацию.

```python
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```
- Оптимизируем загрузку данных для ускорения обучения.

---

## **6. Создание модели CNN**
```python
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(class_names), activation='softmax'),
])
```
- Последовательно создаем слои нейросети.

---

## **7. Компиляция и обучение**
```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_ds, validation_data=val_ds, epochs=10)
```
- Компилируем и обучаем модель.

---

## **8. Оценка модели**
```python
y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))
```
- Получаем предсказания модели.

```python
conf_mat = confusion_matrix(y_true, y_pred)
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.show()
```
- Строим матрицу ошибок.

```python
print(classification_report(y_true, y_pred, target_names=class_names))
```
- Выводим отчет.

### **Разбор параметров функции `tf.keras.preprocessing.image_dataset_from_directory()`**

Функция `tf.keras.preprocessing.image_dataset_from_directory()` загружает изображения из указанной директории и автоматически разделяет их на батчи для обучения нейросети.  

#### **Полный вызов в коде:**
```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)
```
🔍 Разберем **каждый параметр**:

---

### **1. `data_dir`**
- **Тип:** `str` или `pathlib.Path`
- **Значение в коде:** `data_dir`
- **Описание:**  
  Указывает путь к папке, содержащей изображения, сгруппированные по подпапкам.  
  - Каждая подпапка соответствует отдельному классу.
  - TensorFlow автоматически определяет классы по именам папок.

📌 **Пример структуры данных:**
```
data_dir/
│── Hematogenic_type/ (карие глаза)
│   ├── img_1.jpg
│   ├── img_2.jpg
│── Lymphoid_type/ (голубые, серые глаза)
│   ├── img_3.jpg
│   ├── img_4.jpg
│── Mixed_type/ (зелёные, жёлтые глаза)
│   ├── img_5.jpg
│   ├── img_6.jpg
```
**TensorFlow автоматически распознает классы:**  
```python
class_names = train_ds.class_names
print(class_names) 
# ['Hematogenic_type', 'Lymphoid_type', 'Mixed_type']
```

---

### **2. `validation_split=0.2`**
- **Тип:** `float`
- **Значение в коде:** `0.2`
- **Описание:**  
  Определяет, какая **доля данных** будет использована для валидации (20% = 0.2).
  - 80% данных (`subset="training"`) пойдут в `train_ds`.
  - 20% данных (`subset="validation"`) пойдут в `val_ds`.

---

### **3. `subset="training"`**
- **Тип:** `str`
- **Значение в коде:** `"training"`
- **Допустимые значения:** `"training"` или `"validation"`
- **Описание:**  
  Указывает, какую часть данных (обучающую или валидационную) загружать.  
  - `subset="training"` → Загружает **80%** изображений (для обучения).
  - `subset="validation"` → Загружает **20%** изображений (для валидации).

📌 **Важно!**  
- Если используем `validation_split`, нужно **указывать этот параметр** (иначе ошибка).  
- Значения `"training"` и `"validation"` должны быть **одинаковыми** при загрузке `train_ds` и `val_ds`.

---

### **4. `seed=123`**
- **Тип:** `int`
- **Значение в коде:** `123`
- **Описание:**  
  **Фиксирует случайное разбиение** данных на обучение/валидацию.  
  - Если **не указать `seed`**, разбиение будет разным при каждом запуске.
  - При одинаковом `seed=123` данные будут **разбиваться одинаково** при каждом запуске.

📌 **Зачем нужен `seed`?**  
- Для воспроизводимости результатов (чтобы обучение и валидация всегда имели одни и те же изображения).
- Особенно важно при **сравнении моделей**.

---

### **5. `image_size=(img_height, img_width)`**
- **Тип:** `tuple` из двух `int`
- **Значение в коде:** `(180, 180)`
- **Описание:**  
  **Приводит изображения к фиксированному размеру** `(180, 180)`, что делает их совместимыми с моделью.
  - Если изображения разные по размеру, их **масштабируют автоматически**.
  - Входные слои CNN требуют, чтобы все изображения были одинаковыми.

📌 **Пример:**
- Исходное изображение: `300x400` → Изменится на `180x180`
- Исходное изображение: `500x600` → Изменится на `180x180`

---

### **6. `batch_size=batch_size`**
- **Тип:** `int`
- **Значение в коде:** `32`
- **Описание:**  
  Определяет, сколько изображений **подается в модель за один шаг обучения**.  
  - **Большие батчи** (`batch_size=64, 128`) ускоряют обучение, но требуют больше оперативной памяти.
  - **Маленькие батчи** (`batch_size=16, 32`) требуют меньше памяти, но обучение может быть менее стабильным.

📌 **Пример работы батчей (если всего 1000 изображений)**:
- `batch_size=32` → **32 изображения за шаг** (≈32 шага за эпоху)
- `batch_size=64` → **64 изображения за шаг** (≈16 шагов за эпоху)

---

## **⚡ Итог**
Функция загружает изображения, делит их на обучение и валидацию, масштабирует и разбивает на батчи.

📌 **Как применяются параметры в коде?**
```python
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,          # Папка с изображениями, разбитыми по классам
    validation_split=0.2,  # 20% данных уходит на валидацию
    subset="training", # Загружаем только обучающую часть (80%)
    seed=123,          # Фиксируем случайное разбиение для воспроизводимости
    image_size=(180, 180), # Все изображения приводятся к 180x180 пикселей
    batch_size=32      # Обучаем модель на батчах по 32 изображения
)
```

⚡ **Аналогично, загружаем валидационные данные:**
```python
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,          # Та же папка с изображениями
    validation_split=0.2,  # Разбиваем так же
    subset="validation", # Загружаем валидационные данные (20%)
    seed=123,          # То же значение `seed`, чтобы разбиение было идентичным
    image_size=(180, 180), # Все изображения будут 180x180 пикселей
    batch_size=32      # Батч для валидации тоже 32
)
```

💡 **Таким образом,**
- Данные загружаются из папок и автоматически маркируются по классам.
- Делятся на **80% (обучение) и 20% (валидация)**.
- Масштабируются до фиксированного размера **180x180**.
- Разбиваются на **батчи по 32** изображения.

### **Подготовка данных перед подачей в модель**  
Перед тем как обучать нейросеть, необходимо правильно подготовить данные. Это поможет модели работать быстрее, точнее и эффективнее. Разберем **зачем** и **как** выполняются основные шаги.

---

## **1. Нормализация изображений (`Rescaling`)**  
📌 **Что делает этот код?**
```python
normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)
```
**🔹 Проблема:**  
- В изображениях пиксели имеют значения от `0` до `255` (8-битный цвет).  
- Это **слишком большие числа** для нейросети, и она хуже обучается.  

**🔹 Решение:**  
- Функция `Rescaling(1.0 / 255)` делит все пиксели на `255`, переводя их в диапазон `[0,1]`.  
- Это делает обучение **более стабильным** и ускоряет работу сети.

📌 **Пример преобразования:**
| Исходный пиксель | После нормализации |
|------------------|--------------------|
| 0 (чёрный)       | 0.0                |
| 128 (серый)      | 0.5                |
| 255 (белый)      | 1.0                |

👉 **Зачем это нужно?**  
- Улучшает **сходимость** модели (быстрее достигается минимальная ошибка).  
- Делает значения **более удобными** для вычислений в нейросети.  

---

## **2. Применение нормализации к датасету**
📌 **Что делает этот код?**
```python
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
```
**🔹 Как это работает?**  
- `train_ds.map(...)` применяет **функцию нормализации** ко всем изображениям в обучающем и валидационном датасетах.  
- Теперь модель будет получать **нормализованные** изображения.

👉 **Зачем это нужно?**  
- Упрощает обучение модели.  
- Данные в **разных батчах** будут в одинаковом диапазоне `[0,1]`, что делает обучение **более стабильным**.

---

## **3. Оптимизация загрузки данных**
📌 **Что делает этот код?**
```python
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```
### **🔹 Разберем каждую операцию:**
### 1️⃣ `cache()` – кэширование данных в памяти  
```python
train_ds = train_ds.cache()
```
- **Что делает?**  
  - Хранит **обработанные** данные в оперативной памяти (RAM), чтобы их не загружать заново с диска.  
  - Ускоряет обучение, особенно если данных **много**.

- **Когда полезно?**  
  - Если данные **умещаются** в память (например, 1000-5000 изображений).  

---

### 2️⃣ `shuffle(1000)` – перемешивание данных  
```python
train_ds = train_ds.shuffle(1000)
```
- **Что делает?**  
  - **Перемешивает** изображения, чтобы модель **не запоминала порядок**.  
  - Если этого не делать, модель может **запомнить последовательность** и хуже обобщать данные.  

- **Почему `1000`?**  
  - Это число означает, что перемешиваются сразу 1000 изображений.  
  - Чем больше значение – тем лучше перемешивание, но больше расходуется памяти.

---

### 3️⃣ `prefetch(buffer_size=AUTOTUNE)` – загрузка данных в фоновом режиме  
```python
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
```
- **Что делает?**  
  - **Параллельно** загружает следующий батч изображений, пока модель обучается на текущем.  
  - Позволяет **ускорить обучение** за счет **лучшего использования процессора/GPU**.  

- **Что значит `AUTOTUNE`?**  
  - TensorFlow **сам выбирает** оптимальное количество изображений для предзагрузки.  
  - **Не нужно вручную настраивать!**

👉 **Зачем это нужно?**  
- Уменьшает **время простоя** модели (GPU не ждет загрузку данных).  
- Улучшает **производительность обучения**.  

---

## **🛠 Итог: зачем нужна вся подготовка?**
| Шаг | Что делает? | Почему важно? |
|-----|------------|--------------|
| **Нормализация (`Rescaling`)** | Приводит пиксели к диапазону `[0,1]`. | Делает обучение стабильнее и быстрее. |
| **Применение нормализации (`map()`)** | Нормализует все изображения в датасете. | Гарантирует, что модель получает правильные данные. |
| **Кэширование (`cache()`)** | Хранит данные в памяти. | Ускоряет обучение. |
| **Перемешивание (`shuffle()`)** | Перемешивает данные перед обучением. | Помогает модели лучше обобщать данные. |
| **Предзагрузка (`prefetch()`)** | Загружает данные в фоне. | Снижает задержки, ускоряет обучение. |

## **Разбор архитектуры сверточной нейросети (CNN)**  

В коде определена **сверточная нейросеть (Convolutional Neural Network, CNN)** с помощью **Sequential API** в Keras. Давайте подробно разберем **каждый слой**, зачем он нужен и как влияет на обработку изображений.  

---

## **📌 1. Создание модели**
```python
model = tf.keras.Sequential([
```
📌 **Что делает?**  
- Определяет **последовательную (Sequential)** модель, в которой слои идут **друг за другом**.  
- Это означает, что данные будут **проходить через каждый слой** по порядку.  

**🔹 Альтернативные варианты**:  
- Вместо `Sequential` можно использовать `Functional API`, если требуется **сложная архитектура** (разветвления, параллельные слои и т.д.).  

---

## **📌 2. Первый сверточный слой (`Conv2D`)**
```python
tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
```
📌 **Что делает?**  
- Это **сверточный слой** (`Conv2D`), который анализирует изображение, выделяя **ключевые признаки** (края, текстуры и т. д.).  
- `32` – **количество фильтров** (нейронов), анализирующих изображение.  
- `(3, 3)` – **размер ядра (фильтра)**, который скользит по изображению и анализирует его участки.  
- `activation='relu'` – **функция активации** ReLU (отбрасывает отрицательные значения).  
- `input_shape=(img_height, img_width, 3)` – **размер входного изображения** (высота, ширина, 3 канала для RGB).  

📌 **Как работает свертка?**  
- Ядро размером `3x3` перемещается по изображению и вычисляет **новые пиксели** на основе исходных.  
- Например, если на входе `180x180x3`, то после свертки размер будет `178x178x32` (зависит от настроек).  

📌 **Почему `ReLU`?**  
- **Обнуляет** отрицательные значения, оставляя только **значимые** признаки.  
- Ускоряет обучение и **избегает проблемы исчезающего градиента**.  

---

## **📌 3. Первый слой подвыборки (`MaxPooling2D`)**
```python
tf.keras.layers.MaxPooling2D(),
```
📌 **Что делает?**  
- **Уменьшает размер изображения**, сохраняя **самые важные** признаки.  
- Применяет **максимальное объединение (max pooling)** – берёт **наибольшее** значение из соседних пикселей.  
- Обычный размер окна **(2,2)** – делит картинку **на 4 части и берет максимальное значение из каждой**.  

📌 **Пример (матрица 2x2, `MaxPooling` 2x2):**
```
[ 5, 2 ]    ->  5
[ 1, 8 ]        8
```
👉 После `MaxPooling`, изображение уменьшается **в 2 раза** по ширине и высоте.  

📌 **Зачем это нужно?**  
- **Убирает шум**, оставляя **главные признаки**.  
- **Уменьшает вычислительные затраты** – модель обучается быстрее.  

---

## **📌 4. Второй сверточный слой (`Conv2D`)**
```python
tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
tf.keras.layers.MaxPooling2D(),
```
📌 **Что изменилось?**  
- Количество фильтров увеличилось с `32` → `64`.  
- Усложняет поиск признаков – теперь сеть **распознаёт более сложные паттерны**.  
- После `MaxPooling2D()` размер изображения **ещё уменьшается в 2 раза**.  

📌 **Зачем увеличивать фильтры?**  
- **Первый слой** ловит **простые признаки** (линии, контуры).  
- **Второй слой** находит **сложные формы** (глаза, нос, текстуры).  

---

## **📌 5. Третий сверточный слой (`Conv2D`)**
```python
tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
tf.keras.layers.MaxPooling2D(),
```
📌 **Что изменилось?**  
- Теперь **128 фильтров** – еще больше нейронов анализирует изображение.  
- Сеть теперь **видит объекты целиком** (например, форму глаза).  

📌 **Зачем 3 сверточных слоя?**  
- **1 слой** – базовые признаки (границы, точки).  
- **2 слой** – детали (кривые, углы).  
- **3 слой** – сложные структуры (целые объекты).  

---

## **📌 6. Преобразование в плоский вектор (`Flatten`)**
```python
tf.keras.layers.Flatten(),
```
📌 **Что делает?**  
- Преобразует **многомерную карту признаков** в **одномерный вектор**.  
- Готовит данные для **полносвязных слоев** (`Dense`).  

📌 **Пример:**  
Допустим, после последнего `MaxPooling` изображение стало `22x22x128` (ширина, высота, фильтры).  
После `Flatten()` это превращается в **вектор из 22 × 22 × 128 = 61 952 значений**.  

---

## **📌 7. Полносвязный слой (`Dense`)**
```python
tf.keras.layers.Dense(128, activation='relu'),
```
📌 **Что делает?**  
- `128` – **количество нейронов** (скрытый слой).  
- `activation='relu'` – нелинейная функция, усиливающая полезные признаки.  
- Этот слой **анализирует полученные признаки** и учится делать предсказания.  

📌 **Зачем нужен полносвязный слой?**  
- Связывает **все признаки**, чтобы сделать финальный прогноз.  
- Работает как **"мозг", принимающий решение**.  

---

## **📌 8. Выходной слой (`Dense`)**
```python
tf.keras.layers.Dense(len(class_names), activation='softmax'),
```
📌 **Что делает?**  
- `len(class_names)` – количество выходных **классов** (например, `3`, если `Hematogenic`, `Lymphoid`, `Mixed`).  
- `activation='softmax'` – переводит значения в **вероятности**, где сумма = `1.0`.  

📌 **Пример предсказания (`softmax`):**
| Класс  | Вероятность |
|--------|------------|
| Hematogenic | 0.10 |
| Lymphoid | 0.80 |
| Mixed | 0.10 |

👉 **Наибольшая вероятность (`0.80`) – значит, сеть считает, что это `Lymphoid` (голубые глаза).**  

📌 **Зачем `softmax`?**  
- Превращает числа в **вероятности** (от `0` до `1`).  
- Позволяет модели **делать выбор между классами**.  

---

## **🛠 Итог: зачем нужны все слои?**
| Слой | Что делает? | Зачем? |
|------|------------|--------|
| **Conv2D(32, (3,3))** | Находит границы и контуры. | Определяет базовые формы. |
| **MaxPooling2D()** | Уменьшает размер изображения. | Оставляет важное, убирает шум. |
| **Conv2D(64, (3,3))** | Ищет более сложные текстуры. | Распознаёт части объектов. |
| **MaxPooling2D()** | Ещё уменьшает изображение. | Убирает лишнюю информацию. |
| **Conv2D(128, (3,3))** | Распознаёт целые объекты. | Видит сложные формы. |
| **Flatten()** | Превращает признаки в вектор. | Готовит данные для решения. |
| **Dense(128, relu)** | Выделяет главные признаки. | Принимает решение. |
| **Dense(num_classes, softmax)** | Предсказывает класс. | Делает итоговый выбор. |

## **📌 Компиляция и обучение модели в TensorFlow/Keras**  

Теперь разберём строку:  
```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_ds, validation_data=val_ds, epochs=10)
```
Здесь мы **компилируем и обучаем** нейросеть. Разберём **каждый параметр** и шаг этого процесса.  

---

## **🔹 1. Компиляция модели (`compile()`)**
```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```
📌 **Что делает?**  
- **Подготавливает модель** к обучению, выбирая **оптимизатор**, **функцию потерь** и **метрики качества**.  

📌 **Разберём параметры:**
- **`optimizer='adam'`** – алгоритм, который **обновляет веса** нейронов.  
- **`loss='sparse_categorical_crossentropy'`** – функция ошибки (чем меньше, тем лучше).  
- **`metrics=['accuracy']`** – измеряет **точность** модели.  

📌 **Разберём подробнее!** 👇  

### **1.1. Оптимизатор (`adam`)**  
```python
optimizer='adam'
```
- **Оптимизатор** – это алгоритм, который **изменяет веса нейронов**, чтобы минимизировать ошибку.  
- **Adam (Adaptive Moment Estimation)** – самый **популярный** и **быстрый** метод.  

🔹 **Как работает Adam?**  
1. Следит за **средним градиентом** (как "ускорение" в физике).  
2. **Автоматически подбирает** скорость обучения для каждого веса.  
3. **Быстрее находит минимум функции потерь**, чем обычный `SGD`.  

👉 **Почему Adam?**  
- Работает **хорошо почти во всех задачах**.  
- **Не требует ручного подбора** скорости обучения (`learning rate`).  

---

### **1.2. Функция потерь (`sparse_categorical_crossentropy`)**  
```python
loss='sparse_categorical_crossentropy'
```
- Функция потерь **измеряет, насколько предсказания модели далеки от истины**.  
- В этой задаче у нас **классификация нескольких классов** (`Hematogenic`, `Lymphoid`, `Mixed`).  

📌 **Почему именно `sparse_categorical_crossentropy`?**  
- Данные размечены **числовыми метками** (`0, 1, 2`), а не в виде "one-hot" (например, `[1,0,0]`).  
- Если бы классы были представлены в виде `[1,0,0]`, использовалась бы `categorical_crossentropy`.  
- **Кросс-энтропия** – это стандартная функция ошибки для классификации.  

👉 **Как она работает?**  
- Она **сравнивает предсказанные вероятности** (из `softmax`) с **реальными метками классов**.  
- Чем **больше ошибка**, тем сильнее **нейросеть корректирует свои веса**.  

Пример:  
**Истинный класс:** `1 (Lymphoid)`  
**Предсказания модели:** `[0.1, 0.8, 0.1]`  
- Функция потерь покажет **маленькую ошибку** (предсказание близко к истине).  
- Если бы было `[0.8, 0.1, 0.1]`, ошибка была бы **большой**.  

---

### **1.3. Метрика (`accuracy`)**
```python
metrics=['accuracy']
```
- **Метрика** оценивает **качество модели**, но **не влияет на обучение**.  
- **`accuracy` (точность)** – доля **правильно классифицированных** примеров.  

Пример:  
- **100 изображений**  
- **80 правильно классифицированных**  
- **Точность (accuracy) = 80%**  

👉 **Почему важно различать `loss` и `accuracy`?**  
- `loss` – измеряет **ошибку модели** (важно для обучения).  
- `accuracy` – удобна для **оценки качества модели**.  

---

## **🔹 2. Обучение модели (`fit()`)**  
```python
history = model.fit(train_ds, validation_data=val_ds, epochs=10)
```
📌 **Что делает?**  
- Запускает **процесс обучения** модели на `train_ds` (тренировочных данных).  
- Проверяет качество на `val_ds` (валидационных данных).  
- Проходит через **все данные 10 раз** (`epochs=10`).  
- Сохраняет историю обучения в `history` (потом можно строить графики).  

📌 **Разберём параметры:**  
- **`train_ds`** – тренировочные данные (изображения и метки классов).  
- **`validation_data=val_ds`** – проверка на **новых** изображениях.  
- **`epochs=10`** – **сколько раз** пройти через весь датасет.  

👉 **Почему `epochs=10`?**  
- Если `epochs` **слишком мало** – модель **не доучится** (ошибка останется большой).  
- Если `epochs` **слишком много** – модель **переобучится** (запомнит трен. данные, но плохо работает на новых).  
- `10` эпох – **оптимальный старт**, но лучше **анализировать графики ошибки**.  

---

## **🛠 Итог: что происходит в `compile()` и `fit()`?**
| Шаг | Что делает? | Зачем? |
|------|------------|--------|
| `compile()` | Готовит модель к обучению, настраивая алгоритмы. | Выбирает оптимизатор, функцию потерь, метрики. |
| `optimizer='adam'` | Обновляет веса нейронов для минимизации ошибки. | Быстро и эффективно обучает нейросеть. |
| `loss='sparse_categorical_crossentropy'` | Сравнивает предсказания модели с реальными метками. | Помогает модели лучше классифицировать. |
| `metrics=['accuracy']` | Оценивает долю правильных ответов. | Показывает качество работы модели. |
| `fit()` | Запускает процесс обучения. | Обучает модель на данных, корректируя её ошибки. |
| `epochs=10` | Повторяет обучение 10 раз. | Достаточно, чтобы модель хорошо запомнила закономерности. |

Давайте более подробно разберем код, связанный с **оценкой модели**:

### 1. **Получение предсказаний модели**

```python
y_true = []  # Истинные метки классов
y_pred = []  # Предсказанные моделью классы

for images, labels in val_ds:
    preds = model.predict(images)  # Получаем предсказания модели
    y_true.extend(labels.numpy())  # Добавляем истинные метки классов
    y_pred.extend(np.argmax(preds, axis=1))  # Преобразуем вероятности в конкретные классы
```

📌 **Объяснение:**

1. **`y_true = []` и `y_pred = []`** – создаём два списка:  
   - `y_true` будет хранить **истинные метки классов**, то есть реальные классы, к которым принадлежат изображения в валидационном наборе.  
   - `y_pred` будет хранить **предсказания модели**, то есть те классы, которые модель считает наиболее вероятными для каждого изображения.  

2. **Цикл по валидационному датасету (`for images, labels in val_ds`)** – проходим по валидационным данным `val_ds`, которые содержат пары:  
   - **`images`** – изображения, которые подаются в модель для предсказания.  
   - **`labels`** – реальные метки (классы) этих изображений.

3. **`preds = model.predict(images)`** – для каждой партии изображений модель делает предсказания. Функция `model.predict()` возвращает вероятности принадлежности каждого изображения к каждому классу.  
   Например, если у нас 3 класса, для каждого изображения будет список вероятностей, например: `[0.1, 0.7, 0.2]`. Это означает, что модель считает, что это изображение принадлежит ко второму классу с вероятностью 70%.

4. **`y_true.extend(labels.numpy())`** – добавляем в список истинных меток `y_true` реальные метки классов из `labels`. Метод `.numpy()` используется для преобразования тензора TensorFlow в обычный массив NumPy.

5. **`y_pred.extend(np.argmax(preds, axis=1))`** – преобразуем вероятности в **конкретные предсказания**.  
   - Для каждого изображения `preds` содержит вероятности для всех классов.  
   - `np.argmax(preds, axis=1)` находит индекс максимальной вероятности для каждого изображения. Например, если для одного изображения вероятности: `[0.1, 0.7, 0.2]`, то `np.argmax(preds, axis=1)` вернёт `1`, так как второй класс (с индексом 1) имеет наибольшую вероятность.  
   - Эти индексы (классы) добавляются в список `y_pred`.

Таким образом, в итоге у нас будут два списка:  
- **`y_true`** – истинные метки для всех изображений в валидационном наборе.  
- **`y_pred`** – предсказания модели для этих изображений.

---

### 2. **Построение матрицы ошибок (матрицы путаницы)**

```python
conf_mat = confusion_matrix(y_true, y_pred)
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.show()
```

📌 **Объяснение:**

1. **`conf_mat = confusion_matrix(y_true, y_pred)`** – создаём **матрицу путаницы** с помощью функции `confusion_matrix` из библиотеки `sklearn.metrics`.  
   - Эта матрица помогает понять, как модель классифицирует объекты, сравнивая истинные метки `y_true` с предсказанными метками `y_pred`.  
   - Матрица путаницы представляет собой квадратную таблицу, где строки — это **истинные метки**, а столбцы — **предсказанные метки**.  
   Например:
   ```
   |          | Predicted Class 1 | Predicted Class 2 | Predicted Class 3 |
   |----------|-------------------|-------------------|-------------------|
   | True 1   | 50                | 3                 | 2                 |
   | True 2   | 5                 | 40                | 0                 |
   | True 3   | 1                 | 2                 | 60                |
   ```

   - Значение в ячейке (i, j) матрицы путаницы означает количество объектов, которые принадлежат **к классу i**, но были классифицированы как **класс j**.

2. **`sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)`** – строим **тепловую карту** с помощью библиотеки `seaborn`.  
   - **`annot=True`** – добавляет значения в ячейки матрицы.  
   - **`fmt="d"`** – указывает формат чисел (целые числа).  
   - **`cmap="Blues"`** – выбираем цветовую палитру для отображения (в данном случае синий).  
   - **`xticklabels=class_names` и `yticklabels=class_names`** – метки по осям X и Y будут отображать имена классов.  
   Таким образом, матрица будет визуализирована в виде цветной таблицы, где тёмные клетки будут указывать на **большие числа**.

3. **`plt.show()`** – отображаем тепловую карту на экране.

---

### 3. **Вывод отчёта по классификации**

```python
print(classification_report(y_true, y_pred, target_names=class_names))
```

📌 **Объяснение:**

1. **`classification_report(y_true, y_pred, target_names=class_names)`** – выводим **подробный отчёт** по классификации с помощью функции `classification_report` из `sklearn.metrics`.  
   Этот отчёт содержит информацию о точности, полноте и F1-мере для каждого класса.  

   Например, отчёт может выглядеть так:
   ```
                 precision    recall  f1-score   support
   Class 1        0.90        0.85      0.87        100
   Class 2        0.80        0.75      0.77        100
   Class 3        0.95        0.96      0.95        100

   accuracy                           0.85        300
   macro avg       0.88        0.85      0.86        300
   weighted avg    0.88        0.85      0.86        300
   ```

2. **Основные показатели:**
   - **Precision (точность)** – доля верных положительных предсказаний среди всех предсказанных положительных.  
   - **Recall (полнота)** – доля верных положительных предсказаний среди всех реальных положительных объектов.  
   - **F1-score** – гармоническое среднее между точностью и полнотой.  
   - **Support** – количество объектов в каждом классе.

3. **`target_names=class_names`** – указываем имена классов, чтобы они отображались в отчёте вместо числовых меток (например, `Class 1`, `Class 2`).

---

### **Итог:**
- Мы получаем **предсказания модели** для валидационных данных, сравниваем их с истинными метками и строим **матрицу путаницы**, чтобы визуализировать ошибки классификации.  
- Также выводим **подробный отчёт** по классификации, чтобы понять, насколько хорошо модель различает различные классы и где у неё возникают трудности.

Давайте разберем, что означают строки из отчета, который мы выводим с помощью `classification_report`.

### Пример отчета:

```
                 precision    recall  f1-score   support
Class 1        0.90        0.85      0.87        100
Class 2        0.80        0.75      0.77        100
Class 3        0.95        0.96      0.95        100

accuracy                           0.85        300
macro avg       0.88        0.85      0.86        300
weighted avg    0.88        0.85      0.86        300
```

### 1. **Precision (точность)**:
- Точность показывает, насколько верны те прогнозы, которые модель сделала как положительные (то есть, когда она предсказала, что изображение принадлежит к определенному классу). Это мера того, сколько из всех предсказанных положительных примеров действительно являются положительными.
- Например, для **Class 1** точность равна **0.90**, что означает, что 90% изображений, которые модель предсказала как принадлежащие к Class 1, на самом деле принадлежат этому классу.

### 2. **Recall (полнота)**:
- Полнота показывает, насколько модель может обнаружить все истинные положительные объекты (то есть, сколько из всех объектов реального класса модель правильно классифицировала как принадлежащие этому классу).
- Например, для **Class 1** полнота равна **0.85**, что означает, что модель правильно классифицировала 85% всех изображений, которые на самом деле принадлежат к Class 1.

### 3. **F1-score**:
- F1-score — это гармоническое среднее между точностью и полнотой, которое даёт более сбалансированную оценку, особенно когда данные несбалансированы.
- Например, для **Class 1** F1-score равен **0.87**, что является сбалансированной метрикой, комбинирующей как точность, так и полноту.

### 4. **Support**:
- Это просто количество объектов в каждой категории. Это количество примеров, по которым модель делала предсказания.
- Например, для **Class 1** support равен **100**, что означает, что в валидационном наборе данных было 100 изображений, принадлежащих к Class 1.

---

### Строки "accuracy", "macro avg" и "weighted avg":

1. **accuracy**:
   - **accuracy = 0.85** — это общая **точность** модели на всех данных. В данном случае модель верно классифицировала **85%** всех изображений в валидационном наборе.
   - Эта метрика рассчитывается как:
     \[
     \text{Accuracy} = \frac{\text{Количество верных предсказаний}}{\text{Общее количество примеров}}
     \]
   - В данном случае это означает, что модель верно классифицировала 255 из 300 изображений (85%).

2. **macro avg**:
   - **Macro average (среднее по классам)** — это среднее значение точности, полноты и F1-меры по всем классам, при этом для каждого класса все метрики считаются равными. Это значит, что каждый класс вносит одинаковый вклад в итоговую метрику, независимо от того, сколько примеров было в каждом классе.
   - Например, **macro avg precision = 0.88** — это средняя точность по всем классам. То есть, если рассчитать точность для всех классов и взять их среднее, то получится **88%**.
   - **macro avg recall = 0.85** — средняя полнота по всем классам.
   - **macro avg f1-score = 0.86** — средняя F1-метрика по всем классам.

3. **weighted avg**:
   - **Weighted average (взвешенное среднее)** — это среднее значение по всем классам, но с учётом того, сколько объектов было в каждом классе. Это означает, что классы с большим количеством примеров будут влиять на итоговый результат больше, чем классы с меньшим количеством примеров.
   - Например, **weighted avg precision = 0.88** — это взвешенное среднее по точности, которое учитывает количество примеров в каждом классе.
   - **weighted avg recall = 0.85** — взвешенная полнота по всем классам.
   - **weighted avg f1-score = 0.86** — взвешенная F1-метрика по всем классам.

---

### **Подытожим:**

- **`accuracy = 0.85`** — это общая точность модели, она равна 85%.
- **`macro avg`** — это средние значения метрик по всем классам, где каждый класс имеет одинаковый вес.
- **`weighted avg`** — это средние значения метрик, где каждый класс взвешен в зависимости от количества примеров в классе.

Передача `val_ds` в параметр `validation_data` при вызове `model.fit()` важна для того, чтобы модель могла выполнять оценку на валидационных данных на каждой эпохе обучения. 

Вот как это работает:

### Что делает параметр `validation_data`?

- **`train_ds`** — это тренировочные данные, на которых модель учится, обновляя свои веса и минимизируя функцию потерь. 
- **`val_ds`** — это валидационные данные, которые используются для оценки производительности модели на каждом шаге (на каждой эпохе) в процессе обучения.

Когда вы передаете `val_ds` в `validation_data`, это позволяет Keras автоматически:
1. **Проводить оценку модели** на валидационном наборе данных после каждой эпохи.
2. **Отслеживать метрики** (например, точность или потерю) не только на обучающих данных, но и на валидационных. Это помогает вам увидеть, как модель обобщается на новых данных, которые она не видела во время обучения.

### Зачем это нужно?

1. **Предотвращение переобучения (overfitting):**
   - Без валидации модель может слишком подстроиться под тренировочные данные, запоминая их вместо того, чтобы учиться извлекать обобщенные закономерности.
   - Используя валидационные данные, вы можете отслеживать, начинает ли модель переобучаться. Если точность на обучающих данных продолжает расти, но на валидационных остаётся стабильной или падает, это сигнализирует о переобучении.
   
2. **Оценка обобщающих способностей модели:**
   - Валидационные данные дают представление о том, как хорошо модель будет работать на данных, которые не использовались для обучения. Это позволяет лучше понять её способности к обобщению.

3. **Подбор гиперпараметров:**
   - На основе показателей на валидационном наборе данных можно адаптировать гиперпараметры модели, такие как количество эпох, скорость обучения, или архитектуру модели.

### Пример:

Когда вы передаете `val_ds` в `validation_data`, Keras будет выводить информацию о метриках как для тренировочных данных, так и для валидационных. Например:

```python
Epoch 1/10
100/100 [==============================] - 5s 50ms/step - loss: 0.2301 - accuracy: 0.9300 - val_loss: 0.3053 - val_accuracy: 0.9200
```

Здесь:
- **`loss`** и **`accuracy`** — это значения потерь и точности для обучающих данных.
- **`val_loss`** и **`val_accuracy`** — это значения потерь и точности для валидационных данных.

Это помогает вам видеть не только, как модель обучается, но и как она может быть применена в реальных условиях на новых данных.
